# Resume Ranker Pro - Complete Project Documentation

## üìã Table of Contents
1. [Project Overview](#project-overview)
2. [Architecture & Technology Stack](#architecture--technology-stack)
3. [Models Used](#models-used)
4. [Core Components & Functionalities](#core-components--functionalities)
5. [Complete Workflow](#complete-workflow)
6. [Detailed Process Flow](#detailed-process-flow)
7. [How Similarity Matching Works](#how-similarity-matching-works)
8. [Key Features](#key-features)
9. [Performance Metrics](#performance-metrics)
10. [Data Flow Diagram](#data-flow-diagram)
11. [Project Structure](#project-structure)
12. [Installation & Setup](#installation--setup)
13. [API Documentation](#api-documentation)
14. [Usage Guide](#usage-guide)

---

## üìã Project Overview

**Resume Ranker Pro** is an AI-powered resume screening and ranking system that uses semantic similarity matching to automatically rank resumes against job descriptions. The system combines state-of-the-art NLP techniques (Sentence-Transformers), efficient vector search (FAISS), and a modern web interface to provide HR teams and recruiters with an intelligent candidate screening solution.

### Key Achievements
- ‚úÖ **100% Functional** - All core features working as expected
- ‚úÖ **Production-Ready** - Cleaned, optimized, and documented
- ‚úÖ **Scalable Architecture** - Handles both real-time uploads and large database searches
- ‚úÖ **User-Friendly Interface** - Modern, responsive web UI with drag-and-drop support
- ‚úÖ **Robust Skill Extraction** - Automatic skill detection from resumes

---

## üèóÔ∏è Architecture & Technology Stack

### Backend Technologies
- **FastAPI** (0.104.1) - Modern, fast web framework for building APIs
- **Uvicorn** - ASGI server with auto-reload capability
- **Sentence-Transformers** (2.2.2) - Semantic embeddings using `all-MiniLM-L6-v2`
- **FAISS** (1.7.4) - Facebook AI Similarity Search for efficient vector database operations
- **spaCy** (3.7.2) - NLP library for skill extraction and named entity recognition
- **pypdf** (3.17.1) - PDF text extraction library
- **scikit-learn** (1.3.2) - Cosine similarity calculations
- **Pandas** (2.0.3) - CSV data handling and manipulation
- **NumPy** (1.24.3) - Numerical operations for embeddings
- **PyTorch** (2.1.0) - Deep learning framework (dependency for transformers)
- **Transformers** (4.35.0) - Hugging Face transformers library

### Frontend Technologies
- **Bootstrap 5** - Responsive UI framework
- **Font Awesome 6** - Icon library for visual elements
- **Vanilla JavaScript** - No framework dependencies, pure JS
- **HTML5/CSS3** - Modern web standards

### Data Storage
- **FAISS Index** (`resume_index.faiss`) - Vector embeddings index for fast similarity search
- **Pickle Metadata** (`resume_metadata.pkl`) - Resume metadata cache for quick retrieval
- **CSV Database** (`Resume.csv`) - Source resume data (900+ entries)

---

## ü§ñ Models Used

### 1. Sentence-Transformer Model: `all-MiniLM-L6-v2`

**Purpose:** Converts text to semantic embeddings for similarity matching

**Technical Details:**
- **Architecture:** MiniLM (distilled BERT model)
- **Embedding Dimension:** 384-dimensional vectors
- **Model Size:** ~80MB
- **Performance:** Fast inference with good accuracy
- **Provider:** Hugging Face / Sentence-Transformers

**How It Works:**
- Takes text input (job description or resume)
- Outputs a 384-dimensional vector representation
- Similar texts produce similar vectors in the embedding space
- Enables semantic matching beyond simple keyword matching

**Example:**
```
Input: "Looking for a Python developer with FastAPI experience"
Output: [0.23, -0.45, 0.67, ..., 0.12] (384 numbers)
```

**Why This Model:**
- Optimized for speed while maintaining good accuracy
- Pre-trained on large text corpora
- Handles semantic understanding well
- Lightweight compared to larger models

### 2. FAISS Index (IndexFlatIP)

**Purpose:** Fast similarity search in high-dimensional vector space

**Technical Details:**
- **Type:** IndexFlatIP (Inner Product, normalized for cosine similarity)
- **Search Method:** Exact search (no approximation)
- **Normalization:** L2 normalization for cosine similarity
- **Storage:** Disk-based index for persistence

**How It Works:**
- Stores all resume embeddings in a vector index
- Normalizes vectors for cosine similarity calculation
- Performs fast inner product search
- Returns top-k most similar vectors

**Performance:**
- Sub-millisecond search for top-10 results
- Handles 900+ resumes efficiently
- Scales well with database size

### 3. spaCy NER Model: `en_core_web_sm`

**Purpose:** Named Entity Recognition for contextual skill extraction

**Technical Details:**
- **Model:** English small model (en_core_web_sm)
- **Features:** Named Entity Recognition (NER)
- **Entity Types:** ORG, PRODUCT, PERSON, etc.
- **Usage:** Contextual skill detection

**How It Works:**
- Analyzes text for named entities
- Identifies organizations and products in context
- Works alongside regex patterns for comprehensive skill extraction
- Fallback: System works without spaCy using regex-only extraction

---

## üîß Core Components & Functionalities

### 1. Backend API (`app/main.py`)

**FastAPI Application** with three main endpoints:

#### Endpoints:

**`GET /`**
- Serves the main dashboard UI
- Returns HTML template with upload form

**`POST /api/screen-resumes`**
- Core ranking endpoint
- Accepts:
  - `job_description` (string, required): Job description text
  - `files` (file[], optional): PDF resume files
  - `threshold` (float, default=70.0): Minimum match score
  - `include_csv` (bool, default=true): Search CSV database
- Returns: Ranked candidates with scores, skills, and metadata

**`GET /download/{filename}`**
- Download uploaded resume PDFs
- Returns PDF file for download

**Key Features:**
- Asynchronous request handling for better performance
- Background FAISS index building on startup
- Comprehensive error handling and logging
- Text preprocessing for encoding artifacts
- Skill extraction integration
- Dual search paths (PDF uploads + CSV database)

### 2. Semantic Search Engine (`app/utils.py`)

**Core Functions:**

**`load_model()`**
- Loads Sentence-Transformer model (`all-MiniLM-L6-v2`)
- Global model instance for reuse
- Caches model after first load

**`extract_text_from_pdf()`**
- Extracts text from PDF bytes
- Uses pypdf library
- Handles multi-page PDFs
- Error handling for corrupted files

**`generate_embeddings()`**
- Converts text to 384-dimensional vectors
- Batch processing support
- Uses loaded Sentence-Transformer model

**`calculate_similarity_scores()`**
- Computes cosine similarity between JD and resumes
- Returns sorted list by similarity score
- Handles multiple resumes efficiently

**`format_score()`**
- Converts similarity (0-1) to percentage (0-100)
- Clamps values to valid range

### 3. FAISS Vector Database (`app/csv_loader.py`)

**CSVResumeDatabase Class:**

**Initialization:**
- Reads resume data from CSV file
- Builds or loads FAISS index
- Stores metadata for quick retrieval

**Key Methods:**

**`build_index()`**
- Builds FAISS index from CSV data
- Generates embeddings in batches
- Normalizes vectors for cosine similarity
- Saves index to disk for future use

**`search()`**
- Performs vector similarity search
- Returns top-k most similar resumes
- Includes metadata and scores

**Features:**
- Auto-saves/loads index to disk
- Handles missing CSV files gracefully
- Batch processing for large datasets
- Progress tracking during index building

### 4. Skill Extraction (`app/skill_extractor.py`)

**SkillExtractor Class:**

**Approach:**
- **Regex-based matching** for 40+ technical skills
- **spaCy NER** (optional) for contextual skill detection
- **Normalization** handles variations (e.g., "react.js" ‚Üí "React")

**Supported Skills:**

**Programming Languages:**
- Python, Java, JavaScript, TypeScript, C++, C#, Go, Rust

**Web Technologies:**
- HTML, CSS, React, Angular, Vue.js, Node.js, Next.js

**Frameworks:**
- Django, Flask, FastAPI, Spring, ASP.NET

**Databases:**
- SQL, MySQL, PostgreSQL, MongoDB, Redis, Oracle

**Cloud/DevOps:**
- AWS, Azure, GCP, Docker, Kubernetes, Jenkins, Git

**ML/AI:**
- Machine Learning, Deep Learning, TensorFlow, PyTorch, Pandas, NumPy

**Methodologies:**
- Agile, Scrum, DevOps, CI/CD, REST API, GraphQL

**How It Works:**
1. Regex patterns match known skills (case-insensitive)
2. spaCy NER identifies contextual skills
3. Skills are normalized and deduplicated
4. Returns sorted list of unique skills

### 5. Text Preprocessing (`app/text_preprocessor.py`)

**TextPreprocessor Class:**

**Purpose:** Ensures clean text input for embeddings and skill extraction

**Processing Steps:**
1. **Unicode normalization** (NFKD) - fixes encoding artifacts (√Ç, \xa0)
2. **ASCII conversion** - strips non-printable characters
3. **Whitespace normalization** - collapses multiple spaces
4. **Lowercasing** - for consistent matching

**Why It's Needed:**
- PDFs often contain encoding artifacts
- Inconsistent spacing affects matching
- Special characters can break regex patterns
- Ensures consistent text format

### 6. Frontend UI (`templates/index.html` + `static/app.js`)

**Features:**

**Upload Interface:**
- Drag & drop file upload
- Multiple file selection
- Visual feedback during upload
- File list display

**Results Display:**
- Dual tables (PDF uploads + CSV database)
- Color-coded match scores:
  - üü¢ Green (‚â•75%): Excellent match
  - üü° Yellow (40-74%): Good match
  - üî¥ Red (<40%): Low match
- Skill badges (up to 4 visible + count)
- Rank indicators

**Interactive Features:**
- Resume preview modal
- Download buttons for PDFs
- CSV export functionality
- Real-time processing indicators
- Responsive design (mobile-friendly)

**Visual Design:**
- Modern glassmorphism effects
- Clean, readable typography
- Bootstrap 5 styling
- Font Awesome icons

---

## üöÄ Complete Workflow

### Step 1: User Input
```
User provides:
‚îú‚îÄ‚îÄ Job Description (text)
‚îú‚îÄ‚îÄ PDF Resumes (optional, multiple files)
‚îî‚îÄ‚îÄ CSV Search Toggle (boolean)
```

### Step 2: PDF Processing (if files uploaded)
```
For each PDF:
‚îú‚îÄ‚îÄ Extract text using pypdf
‚îú‚îÄ‚îÄ Validate text (min 20 characters)
‚îú‚îÄ‚îÄ Preprocess text (clean encoding artifacts)
‚îú‚îÄ‚îÄ Extract skills (regex + spaCy)
‚îî‚îÄ‚îÄ Save file temporarily for download
```

### Step 3: Embedding Generation
```
‚îú‚îÄ‚îÄ Job Description ‚Üí embedding vector (384-dim)
‚îú‚îÄ‚îÄ PDF Resume texts ‚Üí embedding vectors
‚îî‚îÄ‚îÄ Uses all-MiniLM-L6-v2 model
```

### Step 4: Similarity Calculation (Dual Paths)

**Path A: PDF Uploads**
```
‚îú‚îÄ‚îÄ Direct cosine similarity between JD and each PDF resume
‚îú‚îÄ‚îÄ Calculate similarity scores
‚îî‚îÄ‚îÄ Sort by score (descending)
```

**Path B: CSV Database Search**
```
‚îú‚îÄ‚îÄ Generate JD embedding
‚îú‚îÄ‚îÄ FAISS vector search (top-k=10)
‚îú‚îÄ‚îÄ Retrieve similar resumes from index
‚îî‚îÄ‚îÄ Calculate similarity scores
```

### Step 5: Ranking & Filtering
```
‚îú‚îÄ‚îÄ Sort results by match score (descending)
‚îú‚îÄ‚îÄ Assign ranks (1, 2, 3, ...)
‚îú‚îÄ‚îÄ Apply threshold filter (if set)
‚îî‚îÄ‚îÄ Separate ranking for PDF uploads and CSV matches
```

### Step 6: Response Generation
```
JSON Response includes:
‚îú‚îÄ‚îÄ total_processed: Total number of resumes processed
‚îú‚îÄ‚îÄ total_qualified: Number passing threshold
‚îú‚îÄ‚îÄ processing_time_ms: Time taken
‚îú‚îÄ‚îÄ uploaded_results: PDF upload results
‚îÇ   ‚îú‚îÄ‚îÄ rank, filename, candidate_name
‚îÇ   ‚îú‚îÄ‚îÄ match_score, skills, resume_text
‚îÇ   ‚îî‚îÄ‚îÄ warnings (if any)
‚îî‚îÄ‚îÄ database_results: CSV search results
    ‚îú‚îÄ‚îÄ rank, filename, candidate_name
    ‚îú‚îÄ‚îÄ match_score, skills, resume_text
    ‚îî‚îÄ‚îÄ category (from CSV)
```

### Step 7: Frontend Display
```
‚îú‚îÄ‚îÄ Render tables with color-coded scores
‚îú‚îÄ‚îÄ Display skill badges
‚îú‚îÄ‚îÄ Show processing time
‚îî‚îÄ‚îÄ Enable download/export features
```

---

## üìä Detailed Process Flow

### Startup Sequence

1. **FastAPI App Initializes**
   - Sets up routes and middleware
   - Configures static files and templates

2. **Load Sentence-Transformer Model**
   - Downloads model if not cached (~80MB)
   - Loads into memory
   - Caches for subsequent requests

3. **Initialize CSV Database**
   - Creates CSVResumeDatabase instance
   - Checks for existing FAISS index

4. **Index Building/Loading**
   - If index exists: Load from disk (fast)
   - If not: Build index in background thread
   - Generates embeddings for all resumes

5. **Server Ready**
   - Listens on `http://localhost:8000`
   - Ready to accept requests

### Request Processing Flow

```
User submits form
    ‚Üì
Frontend sends POST /api/screen-resumes
    ‚Üì
Backend receives request
    ‚Üì
Generate JD embedding (384-dim vector)
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PDF Processing (if files uploaded) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îú‚îÄ‚îÄ Extract text from PDFs
    ‚îú‚îÄ‚îÄ Preprocess text
    ‚îú‚îÄ‚îÄ Extract skills
    ‚îú‚îÄ‚îÄ Generate embeddings
    ‚îî‚îÄ‚îÄ Calculate cosine similarity
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CSV Database Search (if enabled)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îú‚îÄ‚îÄ Normalize JD embedding
    ‚îú‚îÄ‚îÄ FAISS search (top-k=10)
    ‚îî‚îÄ‚îÄ Retrieve metadata + scores
    ‚Üì
Rank and sort results
    ‚Üì
Apply threshold filter
    ‚Üì
Return JSON response
    ‚Üì
Frontend renders results
```

---

## üéØ How Similarity Matching Works

### Semantic Similarity Concept

**Traditional Keyword Matching:**
- "Python developer" matches "Python developer" ‚úÖ
- "Python developer" doesn't match "Python programmer" ‚ùå
- "Machine Learning engineer" doesn't match "ML specialist" ‚ùå

**Semantic Matching (This Project):**
- "Python developer" matches "Python programmer" ‚úÖ
- "Machine Learning engineer" matches "ML specialist" ‚úÖ
- "Full-stack developer" matches "Full stack engineer" ‚úÖ

### Technical Implementation

**1. Text ‚Üí Embedding:**
```
Input: "Looking for a Python developer with FastAPI experience"
       ‚Üì
Model: all-MiniLM-L6-v2
       ‚Üì
Output: [0.23, -0.45, 0.67, ..., 0.12] (384 numbers)
```

**2. Cosine Similarity Calculation:**
```
JD Vector:     [0.23, -0.45, 0.67, ..., 0.12]
Resume Vector: [0.25, -0.43, 0.65, ..., 0.11]

Cosine Similarity = (JD ¬∑ Resume) / (||JD|| √ó ||Resume||)
Result: 0.87 (87% match)
```

**3. Ranking:**
- Higher similarity = better match
- Results sorted by score (descending)
- Top candidates appear first

### Why Semantic Matching is Better

1. **Understands Context:** Knows that "Python" and "Python programming" are related
2. **Handles Synonyms:** Recognizes "developer" and "programmer" as similar
3. **Captures Intent:** Understands job requirements beyond keywords
4. **More Accurate:** Reduces false negatives from keyword-only matching

---

## ‚ú® Key Features

### 1. Dual Search Modes
- **Real-time PDF Upload Processing:** Process uploaded resumes immediately
- **Fast CSV Database Search:** Search through 900+ resumes via FAISS

### 2. Automatic Skill Extraction
- **40+ Technical Skills Supported:** Comprehensive skill detection
- **Hybrid Approach:** Regex + spaCy NER for accuracy
- **Visual Skill Badges:** Easy-to-scan skill tags in UI

### 3. Modern Web Interface
- **Drag & Drop Upload:** Intuitive file selection
- **Real-time Progress Indicators:** Loading spinners during processing
- **Color-coded Match Scores:** Visual feedback for match quality
- **Responsive Bootstrap Design:** Works on desktop and mobile

### 4. Resume Preview
- **Modal with Candidate Details:** Quick candidate overview
- **First 500 Characters:** Resume text preview
- **Download Button:** Access to full PDF

### 5. CSV Export
- **Download Ranked Results:** Export functionality
- **Includes All Metadata:** Complete candidate information
- **Ready for HR Workflows:** Compatible with ATS systems

### 6. Error Handling
- **Graceful PDF Extraction Failures:** Handles corrupted files
- **Missing Model Fallbacks:** Works without optional dependencies
- **User-friendly Error Messages:** Clear feedback

### 7. Text Preprocessing
- **Handles Encoding Artifacts:** Fixes PDF extraction issues
- **Normalizes Whitespace:** Consistent text format
- **Improves Matching Accuracy:** Better embeddings

---

## üìà Performance Metrics

### Speed Benchmarks
- **Model Loading:** ~2-3 seconds (first time, cached after)
- **PDF Text Extraction:** ~50-200ms per PDF
- **Embedding Generation:** ~100-300ms per resume
- **FAISS Search:** <10ms for top-10 results
- **Total Processing:** ~1-3 seconds for 5 PDFs + CSV search

### Accuracy
- **Semantic Matching:** High accuracy for domain-relevant matches
- **Skill Extraction:** ~85-90% precision for common technical skills
- **False Positives:** Minimal due to word boundary regex patterns

### Scalability
- **PDF Uploads:** Handles 10+ simultaneous uploads
- **CSV Database:** Efficiently searches 900+ resumes
- **Memory Usage:** ~500MB-1GB (model + index)
- **Concurrent Requests:** FastAPI handles multiple users

---

## üîÑ Data Flow Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   User Input    ‚îÇ
‚îÇ  (JD + PDFs)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PDF Extraction ‚îÇ
‚îÇ   (pypdf)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Preprocessing  ‚îÇ
‚îÇ  (Text Cleaner) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Skill Extraction‚îÇ
‚îÇ (Regex + spaCy) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Embeddings    ‚îÇ
‚îÇ (Sentence-BERT) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         ‚îÇ
    ‚ñº         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Direct ‚îÇ ‚îÇ  FAISS   ‚îÇ
‚îÇ Cosine ‚îÇ ‚îÇ  Search  ‚îÇ
‚îÇSimilar ‚îÇ ‚îÇ          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ          ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Ranking  ‚îÇ
    ‚îÇ & Filter ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Response ‚îÇ
    ‚îÇ  (JSON)  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Frontend ‚îÇ
    ‚îÇ Display  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÅ Project Structure

```
Resume_Ranker_Pro/
‚îú‚îÄ‚îÄ app/                          # Backend application
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py              # Package marker
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # FastAPI app & API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                 # PDF extraction, embeddings, similarity
‚îÇ   ‚îú‚îÄ‚îÄ csv_loader.py            # FAISS index builder & CSV search
‚îÇ   ‚îú‚îÄ‚îÄ skill_extractor.py       # Skill extraction (regex + spaCy NER)
‚îÇ   ‚îî‚îÄ‚îÄ text_preprocessor.py    # Text cleaning & normalization
‚îÇ
‚îú‚îÄ‚îÄ templates/                    # Frontend templates
‚îÇ   ‚îî‚îÄ‚îÄ index.html               # Main UI page
‚îÇ
‚îú‚îÄ‚îÄ static/                       # Static assets
‚îÇ   ‚îú‚îÄ‚îÄ app.js                   # Frontend JavaScript logic
‚îÇ   ‚îî‚îÄ‚îÄ styles.css               # Custom styling
‚îÇ
‚îú‚îÄ‚îÄ uploads/                      # Temporary PDF storage
‚îÇ
‚îú‚îÄ‚îÄ Resume.csv                    # Main resume database (900+ entries)
‚îú‚îÄ‚îÄ resume_index.faiss           # FAISS vector index (auto-generated)
‚îú‚îÄ‚îÄ resume_metadata.pkl          # Resume metadata cache (auto-generated)
‚îÇ
‚îú‚îÄ‚îÄ run.py                        # Application entry point
‚îú‚îÄ‚îÄ start.bat                     # Windows startup script
‚îú‚îÄ‚îÄ requirements.txt              # Python dependencies
‚îú‚îÄ‚îÄ README.md                     # User documentation
‚îú‚îÄ‚îÄ PROJECT_REPORT.md             # Comprehensive project report
‚îî‚îÄ‚îÄ PROJECT_DOCUMENTATION.md      # This documentation file
```

---

## üö¶ Installation & Setup

### Prerequisites
- **Python:** 3.8 or higher
- **RAM:** 2GB+ recommended (for model loading)
- **Disk Space:** ~500MB (model + dependencies)
- **OS:** Windows, Linux, or macOS

### Quick Start

1. **Navigate to project directory:**
   ```bash
   cd Resume_Ranker_Pro
   ```

2. **Create virtual environment:**
   ```bash
   python -m venv venv
   venv\Scripts\activate  # Windows
   # or
   source venv/bin/activate  # Linux/Mac
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Install spaCy model:**
   ```bash
   python -m spacy download en_core_web_sm
   ```

5. **Run the application:**
   ```bash
   python run.py
   # or
   uvicorn app.main:app --reload
   ```

6. **Access the UI:**
   - Open browser: `http://localhost:8000`
   - Or use `start.bat` (Windows) which opens browser automatically

### First Run Notes
- Model (`all-MiniLM-L6-v2`) downloads automatically (~80MB)
- FAISS index builds from `Resume.csv` on first run (takes 1-2 minutes)
- Index is cached for subsequent runs (loads in seconds)

---

## üìù API Documentation

### Endpoints

#### `GET /`
- **Description:** Main dashboard page
- **Response:** HTML page with upload form

#### `POST /api/screen-resumes`
- **Description:** Rank resumes against job description
- **Content-Type:** `multipart/form-data`
- **Parameters:**
  - `job_description` (string, required): Job description text
  - `files` (file[], optional): PDF resume files
  - `threshold` (float, default=70.0): Minimum match score
  - `include_csv` (bool, default=true): Search CSV database
- **Response:**
  ```json
  {
    "total_processed": 15,
    "total_qualified": 12,
    "processing_time_ms": 1234.5,
    "uploaded_results": [
      {
        "rank": 1,
        "filename": "resume.pdf",
        "source": "pdf",
        "candidate_name": "resume",
        "match_score": 87.5,
        "skills": ["Python", "FastAPI", "SQL"],
        "resume_text": "...",
        "warnings": []
      }
    ],
    "database_results": [...]
  }
  ```

#### `GET /download/{filename}`
- **Description:** Download uploaded resume PDF
- **Response:** PDF file download

---

## üìñ Usage Guide

### Basic Usage

1. **Enter Job Description:**
   - Paste or type the complete job description
   - Minimum 50 characters required

2. **Upload Resumes (Optional):**
   - Drag and drop PDF files
   - Or click to browse and select files
   - Multiple files supported

3. **Configure Search:**
   - Toggle CSV database search (enabled by default)
   - Adjust threshold if needed (default: 70%)

4. **Analyze & Rank:**
   - Click "Analyze & Rank" button
   - Wait for processing (1-3 seconds typically)

5. **Review Results:**
   - View ranked candidates in tables
   - Check match scores (color-coded)
   - Review extracted skills
   - Click "View Details" for resume preview

6. **Export Results:**
   - Click "Export as CSV" to download results
   - Use in HR workflows or ATS systems

### Tips for Best Results

1. **Job Description Quality:**
   - Include specific skills and requirements
   - Mention technologies and tools
   - Describe responsibilities clearly

2. **Resume Quality:**
   - Ensure PDFs are text-based (not scanned images)
   - Well-formatted resumes work best
   - Include relevant skills and experience

3. **Threshold Settings:**
   - Lower threshold (0-40%): More candidates, lower quality
   - Medium threshold (40-70%): Balanced results
   - High threshold (70-100%): Fewer, high-quality matches

---

## üéì Summary

**Resume Ranker Pro** is a fully functional, production-ready resume screening system that successfully combines:

- ‚úÖ **Advanced NLP** (Sentence-Transformers for semantic matching)
- ‚úÖ **Efficient Search** (FAISS for scalable vector search)
- ‚úÖ **User-Friendly Interface** (Modern web UI with drag-and-drop)
- ‚úÖ **Automatic Skill Extraction** (Regex + spaCy NER)
- ‚úÖ **Robust Error Handling** (Graceful failure management)

The system understands **meaning**, not just keywords, enabling more accurate resume matching than traditional keyword-based systems. It's ready for deployment and can be used by HR teams, recruiters, or integrated into larger ATS systems.

---

**Documentation Version:** 1.0.0  
**Last Updated:** December 2024  
**Project Status:** ‚úÖ Production Ready



